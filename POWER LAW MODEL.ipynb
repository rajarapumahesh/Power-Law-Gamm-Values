{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1494252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import csv\n",
    "from scipy.optimize import fmin\n",
    "\n",
    "# Close all figures\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Define the folder paths\n",
    "original_folder = r\"C:\\Users\\MAHESH\\Desktop\\SRFP INTERNSHIP\\train_in_1\\Raw\"  # Replace with the path to the original image folder\n",
    "output_folder = r\"C:\\Users\\MAHESH\\Desktop\\SRFP INTERNSHIP\\train_in_1\\Done\"  # Replace with the path to the output image folder\n",
    "csv_file_path = r\"C:\\Users\\MAHESH\\Desktop\\SRFP INTERNSHIP\\REPORTS\\gamma_values.csv\"  # Replace with the desired path for the CSV file\n",
    "\n",
    "# Get the list of files in the original image folder\n",
    "original_files = os.listdir(original_folder)\n",
    "\n",
    "# Create an empty list to store gamma values\n",
    "gamma_values = []\n",
    "\n",
    "# Iterate over the files and process each image\n",
    "for file in original_files:\n",
    "    # Read the original and output images\n",
    "    original_image_path = os.path.join(original_folder, file)\n",
    "    output_image_path = os.path.join(output_folder, file)\n",
    "    \n",
    "    # Load the original and output images\n",
    "    original_image = cv2.imread(original_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    output_image = cv2.imread(output_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Check if the images are successfully loaded\n",
    "    if original_image is None or output_image is None:\n",
    "        print(f'Failed to load image {file}. Please check the file path.')\n",
    "        continue\n",
    "\n",
    "    # Resize the images to 300x400 pixels\n",
    "    original_image = cv2.resize(original_image, (400, 300))\n",
    "    output_image = cv2.resize(output_image, (400, 300))\n",
    "\n",
    "    # Convert images to double precision\n",
    "    original_image = original_image.astype(np.float64)\n",
    "    output_image = output_image.astype(np.float64)\n",
    "\n",
    "    # Define the objective function to minimize\n",
    "    def objectiveFunction(gamma):\n",
    "        diff = original_image ** gamma - output_image\n",
    "        return np.linalg.norm(diff, 'fro')\n",
    "\n",
    "    # Perform optimization to find the optimal gamma value\n",
    "    initialGuess = 0.6  # Initial guess for gamma\n",
    "    gamma = fmin(objectiveFunction, initialGuess, disp=False)\n",
    "\n",
    "    # Append the gamma value to the list\n",
    "    gamma_values.append(gamma[0])\n",
    "\n",
    "    # Display the optimal gamma value\n",
    "    print(f'Image: {file} - Optimal gamma value: {gamma[0]:.4f}')\n",
    "\n",
    "# Save gamma values to a CSV file\n",
    "with open(csv_file_path, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['Image', 'Gamma'])\n",
    "    for file, gamma in zip(original_files, gamma_values):\n",
    "        writer.writerow([file, gamma])\n",
    "\n",
    "print(f\"Gamma values saved to the CSV file: {csv_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f261c861",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 441s 38s/step - loss: 0.0769\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 448s 46s/step - loss: 0.0542\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 428s 40s/step - loss: 0.0418\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 341s 33s/step - loss: 0.0274\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 441s 43s/step - loss: 0.0128\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 366s 34s/step - loss: 0.0105\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 337s 32s/step - loss: 0.0114\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 426s 42s/step - loss: 0.0092\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 365s 35s/step - loss: 0.0083\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 367s 37s/step - loss: 0.0076\n",
      "1/1 [==============================] - 0s 485ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Set file paths\n",
    "original_folder = r\"C:\\Users\\MAHESH\\Desktop\\SRFP INTERNSHIP\\train_in_1\\Raw\"\n",
    "output_folder = r\"C:\\Users\\MAHESH\\Desktop\\SRFP INTERNSHIP\\train_in_1\\Done\"\n",
    "csv_file_path = r\"C:\\Users\\MAHESH\\Desktop\\SRFP INTERNSHIP\\REPORTS\\gamma_values.csv\"\n",
    "input_image_path = r\"C:\\Users\\MAHESH\\Desktop\\SRFP INTERNSHIP\\SRFP DAILY REPORTS\\SRFP FINAL REPORT\\18901933200 (1).jpg\"\n",
    "\n",
    "# Load gamma values from the CSV file\n",
    "gamma_df = pd.read_csv(csv_file_path)\n",
    "gamma_dict = dict(zip(gamma_df['file_name'], gamma_df['gamma_value']))\n",
    "\n",
    "# Define function to load, resize, and preprocess images\n",
    "def load_images(original_folder, output_folder, file_name):\n",
    "    original_path = os.path.join(original_folder, file_name)\n",
    "    enhanced_path = os.path.join(output_folder, file_name)\n",
    "\n",
    "    original_img = cv2.imread(original_path)\n",
    "    enhanced_img = cv2.imread(enhanced_path)\n",
    "\n",
    "    # Resize images\n",
    "    original_img = cv2.resize(original_img, (500, 500))\n",
    "    enhanced_img = cv2.resize(enhanced_img, (500, 500))\n",
    "\n",
    "    original_img = original_img / 255.0  # Normalize original image\n",
    "    enhanced_img = enhanced_img / 255.0  # Normalize enhanced image\n",
    "\n",
    "    return original_img, enhanced_img\n",
    "\n",
    "# Create the training dataset\n",
    "input_images = []\n",
    "output_images = []\n",
    "gammas = []\n",
    "\n",
    "for file_name in os.listdir(original_folder):\n",
    "    original_img, enhanced_img = load_images(original_folder, output_folder, file_name)\n",
    "    gamma = gamma_dict.get(file_name, 1.0)  # Default gamma value is 1.0 if not found in the dictionary\n",
    "\n",
    "    input_images.append(original_img)\n",
    "    output_images.append(enhanced_img)\n",
    "    gammas.append(gamma)\n",
    "\n",
    "input_images = np.array(input_images)\n",
    "output_images = np.array(output_images)\n",
    "gammas = np.array(gammas)\n",
    "\n",
    "# Define the model architecture\n",
    "def build_model():\n",
    "    input_shape = (500, 500, 3)\n",
    "    input_image = Input(shape=input_shape, name='input_image')\n",
    "    input_gamma = Input(shape=(1,), name='input_gamma')\n",
    "\n",
    "    conv1 = Conv2D(32, 3, activation='relu', padding='same')(input_image)\n",
    "    conv2 = Conv2D(32, 3, activation='relu', padding='same')(conv1)\n",
    "    conv3 = Conv2D(32, 3, activation='relu', padding='same')(conv2)\n",
    "\n",
    "    conv_gamma = tf.repeat(input_gamma, tf.shape(conv3)[1]*tf.shape(conv3)[2])\n",
    "\n",
    "    conv_gamma = tf.reshape(conv_gamma, (-1, tf.shape(conv3)[1], tf.shape(conv3)[2], 1))\n",
    "\n",
    "    concat = concatenate([conv3, conv_gamma], axis=-1)\n",
    "\n",
    "    output = Conv2D(3, 3, activation='sigmoid', padding='same')(concat)\n",
    "\n",
    "    model = Model(inputs=[input_image, input_gamma], outputs=output)\n",
    "    model.compile(optimizer=Adam(lr=0.0001), loss='mse')\n",
    "\n",
    "    return model\n",
    "\n",
    "# Build and train the model\n",
    "model = build_model()\n",
    "model.fit([input_images, gammas], output_images, batch_size=32, epochs=10)\n",
    "\n",
    "# Save the model weights\n",
    "model.save_weights('model_weights.h5')\n",
    "\n",
    "# Load the input image, resize, and preprocess it\n",
    "input_img = cv2.imread(input_image_path)\n",
    "input_img = cv2.resize(input_img, (500, 500))\n",
    "input_img = input_img / 255.0  # Normalize input image\n",
    "input_img = np.expand_dims(input_img, axis=0)  # Add batch dimension\n",
    "\n",
    "# Get the optimal gamma value for the input image\n",
    "input_file_name = os.path.basename(input_image_path)\n",
    "optimal_gamma = gamma_dict.get(input_file_name, 1.0)  # Default gamma value is 1.0 if not found in the dictionary\n",
    "\n",
    "# Generate the enhanced image\n",
    "gamma_input = np.array([[optimal_gamma]])  # Convert gamma input to NumPy array\n",
    "enhanced_img = model.predict([input_img, gamma_input])\n",
    "enhanced_img = enhanced_img[0] * 255.0  # Denormalize enhanced image\n",
    "enhanced_img = enhanced_img.astype(np.uint8)\n",
    "\n",
    "# Save the enhanced image\n",
    "output_image_path = os.path.join(output_folder, input_file_name)\n",
    "cv2.imwrite(output_image_path, enhanced_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df82b2f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\MAHESH\\\\Desktop\\\\SRFP INTERNSHIP\\\\train_in_1\\\\Done\\\\18901933200 (1).jpg'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e1098d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Tensors must have same number of dimensions: got 4 and 5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 93>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     96\u001b[0m input_img \u001b[38;5;241m=\u001b[39m input_img\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# Adjust input image dimensions\u001b[39;00m\n\u001b[0;32m     97\u001b[0m gamma \u001b[38;5;241m=\u001b[39m gamma\u001b[38;5;241m.\u001b[39mrepeat(input_img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Repeat gamma values to match batch size\u001b[39;00m\n\u001b[1;32m---> 98\u001b[0m output_img \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output_img, target_img\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m))  \u001b[38;5;66;03m# Adjust target image dimensions\u001b[39;00m\n\u001b[0;32m    100\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\ansel\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36mCustomModel.forward\u001b[1;34m(self, input_image, input_gamma)\u001b[0m\n\u001b[0;32m     67\u001b[0m conv3 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mReLU()(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3(conv2))\n\u001b[0;32m     69\u001b[0m conv_gamma \u001b[38;5;241m=\u001b[39m input_gamma\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m3\u001b[39m)  \u001b[38;5;66;03m# Adjust dimensions of conv_gamma\u001b[39;00m\n\u001b[1;32m---> 71\u001b[0m concat \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconv3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconv_gamma\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconcat(concat)\n\u001b[0;32m     73\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigmoid(output)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Tensors must have same number of dimensions: got 4 and 5"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Set file paths\n",
    "original_folder = r\"C:\\Users\\MAHESH\\Desktop\\SRFP INTERNSHIP\\train_in_1\\Raw\"\n",
    "output_folder = r\"C:\\Users\\MAHESH\\Desktop\\SRFP INTERNSHIP\\train_in_1\\Done\"\n",
    "csv_file_path = r\"C:\\Users\\MAHESH\\Desktop\\SRFP INTERNSHIP\\REPORTS\\gamma_values.csv\"\n",
    "input_image_path = r\"C:\\Users\\MAHESH\\Desktop\\SRFP INTERNSHIP\\photo-.jpg\"\n",
    "\n",
    "# Load gamma values from the CSV file\n",
    "gamma_df = pd.read_csv(csv_file_path)\n",
    "gamma_dict = dict(zip(gamma_df['file_name'], gamma_df['gamma_value']))\n",
    "\n",
    "# Define function to load, resize, and preprocess images\n",
    "def load_images(original_folder, output_folder, file_name):\n",
    "    original_path = os.path.join(original_folder, file_name)\n",
    "    enhanced_path = os.path.join(output_folder, file_name)\n",
    "\n",
    "    original_img = cv2.imread(original_path)\n",
    "    enhanced_img = cv2.imread(enhanced_path)\n",
    "\n",
    "    # Resize images\n",
    "    original_img = cv2.resize(original_img, (250, 250))\n",
    "    enhanced_img = cv2.resize(enhanced_img, (250, 250))\n",
    "\n",
    "    original_img = original_img / 255.0  # Normalize original image\n",
    "    enhanced_img = enhanced_img / 255.0  # Normalize enhanced image\n",
    "\n",
    "    return original_img, enhanced_img\n",
    "\n",
    "# Create the training dataset\n",
    "input_images = []\n",
    "output_images = []\n",
    "gammas = []\n",
    "\n",
    "for file_name in os.listdir(original_folder):\n",
    "    original_img, enhanced_img = load_images(original_folder, output_folder, file_name)\n",
    "    gamma = gamma_dict.get(file_name, 1.0)  # Default gamma value is 1.0 if not found in the dictionary\n",
    "\n",
    "    input_images.append(original_img)\n",
    "    output_images.append(enhanced_img)\n",
    "    gammas.append(gamma)\n",
    "\n",
    "input_images = np.array(input_images)\n",
    "output_images = np.array(output_images)\n",
    "gammas = np.array(gammas)\n",
    "\n",
    "# Define the PyTorch model\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv_gamma = nn.Conv2d(1, 32, kernel_size=1, stride=1)\n",
    "        self.concat = nn.Conv2d(64, 3, kernel_size=3, stride=1, padding=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input_image, input_gamma):\n",
    "        conv1 = nn.ReLU()(self.conv1(input_image))\n",
    "        conv2 = nn.ReLU()(self.conv2(conv1))\n",
    "        conv3 = nn.ReLU()(self.conv3(conv2))\n",
    "\n",
    "        conv_gamma = input_gamma.unsqueeze(2).unsqueeze(3)  # Adjust dimensions of conv_gamma\n",
    "\n",
    "        concat = torch.cat((conv3, conv_gamma), dim=1)\n",
    "        output = self.concat(concat)\n",
    "        output = self.sigmoid(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Build and train the PyTorch model\n",
    "model = CustomModel()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "input_images_tensor = torch.from_numpy(input_images).float()\n",
    "output_images_tensor = torch.from_numpy(output_images).float()\n",
    "gammas_tensor = torch.from_numpy(gammas).float()\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(input_images_tensor, gammas_tensor, output_images_tensor)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    for input_img, gamma, target_img in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        input_img = input_img.permute(0, 3, 1, 2)  # Adjust input image dimensions\n",
    "        gamma = gamma.repeat(input_img.shape[0], 1)  # Repeat gamma values to match batch size\n",
    "        output_img = model(input_img, gamma.unsqueeze(1))\n",
    "        loss = criterion(output_img, target_img.permute(0, 3, 1, 2))  # Adjust target image dimensions\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "# Save the model weights\n",
    "torch.save(model.state_dict(), 'model_weights.pth')\n",
    "\n",
    "# Load the input image, resize, and preprocess it\n",
    "input_img = cv2.imread(input_image_path)\n",
    "input_img = cv2.resize(input_img, (250, 250))\n",
    "input_img = input_img / 255.0  # Normalize input image\n",
    "input_img = np.expand_dims(input_img, axis=0)  # Add batch dimension\n",
    "input_img_tensor = torch.from_numpy(input_img).float().permute(0, 3, 1, 2)  # Adjust input image dimensions\n",
    "\n",
    "# Get the optimal gamma value for the input image\n",
    "input_file_name = os.path.basename(input_image_path)\n",
    "optimal_gamma = gamma_dict.get(input_file_name, 1.0)  # Default gamma value is 1.0 if not found in the dictionary\n",
    "gamma_input = torch.tensor([[optimal_gamma]]).float()\n",
    "\n",
    "# Generate the enhanced image\n",
    "with torch.no_grad():\n",
    "    enhanced_img = model(input_img_tensor, gamma_input.unsqueeze(0)).squeeze()\n",
    "enhanced_img = enhanced_img.numpy() * 255.0  # Denormalize enhanced image\n",
    "enhanced_img = enhanced_img.astype(np.uint8)\n",
    "\n",
    "# Save the enhanced image\n",
    "output_image_path = os.path.join(output_folder, input_file_name)\n",
    "cv2.imwrite(output_image_path, enhanced_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e29b27d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "jax requires jaxlib to be installed. See https://github.com/google/jax#installation for installation instructions.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m~\\ansel\\lib\\site-packages\\jax\\_src\\lib\\__init__.py:24\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 24\u001b[0m   \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjaxlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mjaxlib\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'jaxlib'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mjnp\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m grad, jit, vmap\n",
      "File \u001b[1;32m~\\ansel\\lib\\site-packages\\jax\\__init__.py:35\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m _cloud_tpu_init\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Confusingly there are two things named \"config\": the module and the class.\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# We want the exported object to be the class, so we first import the module\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# to make sure a later import doesn't overwrite the class.\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config \u001b[38;5;28;01mas\u001b[39;00m _config_module\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m _config_module\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Force early import, allowing use of `jax.core` after importing `jax`.\u001b[39;00m\n",
      "File \u001b[1;32m~\\ansel\\lib\\site-packages\\jax\\config.py:17\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2018 The JAX Authors.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m \n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# TODO(phawkins): fix users of this alias and delete this file.\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_src\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config\n",
      "File \u001b[1;32m~\\ansel\\lib\\site-packages\\jax\\_src\\config.py:24\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mthreading\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, List, Callable, Hashable, NamedTuple, Iterator, Optional\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_src\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lib\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_src\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m jax_jit\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_src\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transfer_guard_lib\n",
      "File \u001b[1;32m~\\ansel\\lib\\site-packages\\jax\\_src\\lib\\__init__.py:26\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m   \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjaxlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mjaxlib\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m---> 26\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjax requires jaxlib to be installed. See \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://github.com/google/jax#installation for installation instructions.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     29\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m jax\u001b[38;5;241m.\u001b[39mversion\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _minimum_jaxlib_version \u001b[38;5;28;01mas\u001b[39;00m _minimum_jaxlib_version_str\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: jax requires jaxlib to be installed. See https://github.com/google/jax#installation for installation instructions."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import grad, jit, vmap\n",
    "from jax import random, device_put\n",
    "from jax import lax\n",
    "from flax import linen as nn\n",
    "from flax.training import train_state\n",
    "\n",
    "# Set file paths\n",
    "original_folder = r\"C:\\Users\\MAHESH\\Desktop\\SRFP INTERNSHIP\\train_in_1\\Raw\"\n",
    "output_folder = r\"C:\\Users\\MAHESH\\Desktop\\SRFP INTERNSHIP\\train_in_1\\Done\"\n",
    "csv_file_path = r\"C:\\Users\\MAHESH\\Desktop\\SRFP INTERNSHIP\\REPORTS\\gamma_values.csv\"\n",
    "input_image_path = r\"C:\\Users\\MAHESH\\Desktop\\SRFP INTERNSHIP\\train_in_1\\Raw\\DSC_2479.JPG\"\n",
    "\n",
    "# Load gamma values from the CSV file\n",
    "gamma_df = pd.read_csv(csv_file_path)\n",
    "gamma_dict = dict(zip(gamma_df['file_name'], gamma_df['gamma_value']))\n",
    "\n",
    "# Define function to load, resize, and preprocess images\n",
    "def load_images(original_folder, output_folder, file_name):\n",
    "    original_path = os.path.join(original_folder, file_name)\n",
    "    enhanced_path = os.path.join(output_folder, file_name)\n",
    "\n",
    "    original_img = cv2.imread(original_path)\n",
    "    enhanced_img = cv2.imread(enhanced_path)\n",
    "\n",
    "    # Resize images\n",
    "    original_img = cv2.resize(original_img, (500, 500))\n",
    "    enhanced_img = cv2.resize(enhanced_img, (500, 500))\n",
    "\n",
    "    original_img = original_img / 255.0  # Normalize original image\n",
    "    enhanced_img = enhanced_img / 255.0  # Normalize enhanced image\n",
    "\n",
    "    return original_img, enhanced_img\n",
    "\n",
    "# Create the training dataset\n",
    "input_images = []\n",
    "output_images = []\n",
    "gammas = []\n",
    "\n",
    "for file_name in os.listdir(original_folder):\n",
    "    original_img, enhanced_img = load_images(original_folder, output_folder, file_name)\n",
    "    gamma = gamma_dict.get(file_name, 1.0)  # Default gamma value is 1.0 if not found in the dictionary\n",
    "\n",
    "    input_images.append(original_img)\n",
    "    output_images.append(enhanced_img)\n",
    "    gammas.append(gamma)\n",
    "\n",
    "input_images = np.array(input_images)\n",
    "output_images = np.array(output_images)\n",
    "gammas = np.array(gammas)\n",
    "\n",
    "# Define the model architecture\n",
    "class CustomModel(nn.Module):\n",
    "    conv1_filters = 32\n",
    "    conv2_filters = 32\n",
    "    conv3_filters = 32\n",
    "\n",
    "    def setup(self):\n",
    "        self.conv1 = nn.Conv(features=self.conv1_filters, kernel_size=(3, 3), padding=\"SAME\")\n",
    "        self.conv2 = nn.Conv(features=self.conv2_filters, kernel_size=(3, 3), padding=\"SAME\")\n",
    "        self.conv3 = nn.Conv(features=self.conv3_filters, kernel_size=(3, 3), padding=\"SAME\")\n",
    "        self.concat = nn.Conv(features=3, kernel_size=(3, 3), padding=\"SAME\")\n",
    "        self.sigmoid = nn.Activation(nn.sigmoid)\n",
    "\n",
    "    def __call__(self, input_image, input_gamma):\n",
    "        conv1 = nn.relu(self.conv1(input_image))\n",
    "        conv2 = nn.relu(self.conv2(conv1))\n",
    "        conv3 = nn.relu(self.conv3(conv2))\n",
    "\n",
    "        conv_gamma = jnp.repeat(input_gamma, jnp.prod(conv3.shape[1:]))\n",
    "\n",
    "        conv_gamma = jnp.reshape(conv_gamma, (-1, conv3.shape[1], conv3.shape[2], 1))\n",
    "\n",
    "        concat = jnp.concatenate([conv3, conv_gamma], axis=-1)\n",
    "\n",
    "        output = self.concat(concat)\n",
    "        output = self.sigmoid(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "# Build the model\n",
    "rng = random.PRNGKey(0)\n",
    "input_shape = (1, 500, 500, 3)\n",
    "gamma_shape = (1, 1)\n",
    "model = CustomModel()\n",
    "params = model.init(rng, input_image=jnp.ones(input_shape), input_gamma=jnp.ones(gamma_shape))\n",
    "\n",
    "# Define the loss function\n",
    "def mse_loss(output, target):\n",
    "    return jnp.mean(jnp.square(output - target))\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer_def = flax.optim.Adam(learning_rate=0.001)\n",
    "optimizer = optimizer_def.create(params)\n",
    "\n",
    "# Training loop\n",
    "@jax.jit\n",
    "def train_step(optimizer, input_img, target_img, gamma):\n",
    "    def loss_fn(model):\n",
    "        output_img = model(input_img, gamma)\n",
    "        return mse_loss(output_img, target_img)\n",
    "\n",
    "    grad_fn = jax.value_and_grad(loss_fn)\n",
    "    loss, grad = grad_fn(optimizer.target)\n",
    "    optimizer = optimizer.apply_gradient(grad)\n",
    "    return optimizer, loss\n",
    "\n",
    "num_epochs = 10\n",
    "batch_size = 16\n",
    "\n",
    "num_batches = len(input_images) // batch_size\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    for batch in range(num_batches):\n",
    "        start_idx = batch * batch_size\n",
    "        end_idx = start_idx + batch_size\n",
    "\n",
    "        input_batch = input_images[start_idx:end_idx]\n",
    "        output_batch = output_images[start_idx:end_idx]\n",
    "        gamma_batch = gammas[start_idx:end_idx]\n",
    "\n",
    "        input_batch = jnp.array(input_batch)\n",
    "        output_batch = jnp.array(output_batch)\n",
    "        gamma_batch = jnp.array(gamma_batch)\n",
    "\n",
    "        optimizer, loss = train_step(optimizer, input_batch, output_batch, gamma_batch)\n",
    "        epoch_loss += loss\n",
    "\n",
    "    epoch_loss /= num_batches\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {epoch_loss}\")\n",
    "\n",
    "# Save the trained model\n",
    "model_state = optimizer.target\n",
    "flax.serialization.save(model_state, r\"C:\\Users\\MAHESH\\Desktop\\SRFP INTERNSHIP\\train_in_1\\Raw\\DSC_2479vv.JPG\")\n",
    "\n",
    "# Load the trained model\n",
    "model_state = flax.serialization.load(r\"C:\\Users\\MAHESH\\Desktop\\SRFP INTERNSHIP\\train_in_1\\path_to_saved_model\")\n",
    "model = CustomModel()\n",
    "params = model_state.params\n",
    "model = model.apply(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db08810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "model_state = flax.serialization.load(r\"C:\\Users\\MAHESH\\Desktop\\SRFP INTERNSHIP\\train_in_1\\path_to_saved_model\")\n",
    "model = CustomModel()\n",
    "params = model_state.params\n",
    "model = model.apply(params)\n",
    "\n",
    "# Load the input image\n",
    "input_img = cv2.imread(input_image_path)\n",
    "input_img = cv2.resize(input_img, (500, 500))\n",
    "input_img = input_img / 255.0\n",
    "\n",
    "# Prepare the input for the model\n",
    "input_img = jnp.expand_dims(input_img, axis=0)\n",
    "gamma_value = 1.2  # Example gamma value\n",
    "\n",
    "# Convert to JAX arrays\n",
    "input_img = jnp.array(input_img)\n",
    "gamma = jnp.array(gamma_value)\n",
    "\n",
    "# Apply the model to enhance the image\n",
    "enhanced_img = model(input_img, gamma)\n",
    "\n",
    "# Convert the enhanced image back to NumPy array\n",
    "enhanced_img = enhanced_img[0].numpy()\n",
    "enhanced_img = (enhanced_img * 255.0).astype(np.uint8)\n",
    "\n",
    "# Save the enhanced image\n",
    "output_image_path = r\"C:\\Users\\MAHESH\\Desktop\\SRFP INTERNSHIP\\train_in_1\\Raw\\DSC_2479vv.JPG\"\n",
    "cv2.imwrite(output_image_path, enhanced_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44ba50de",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input type (double) and bias type (float) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 94>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     99\u001b[0m gammas \u001b[38;5;241m=\u001b[39m gammas\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m    101\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 102\u001b[0m enhanced_images \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgammas\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(enhanced_images, output_images)\n\u001b[0;32m    104\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\ansel\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36mImageEnhancementModel.forward\u001b[1;34m(self, input_image, input_gamma)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_image, input_gamma):\n\u001b[1;32m---> 73\u001b[0m     conv1 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mReLU()(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_image\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     74\u001b[0m     conv2 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mReLU()(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(conv1))\n\u001b[0;32m     75\u001b[0m     conv3 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mReLU()(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3(conv2))\n",
      "File \u001b[1;32m~\\ansel\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\ansel\\lib\\site-packages\\torch\\nn\\modules\\conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\ansel\\lib\\site-packages\\torch\\nn\\modules\\conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    457\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    458\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Input type (double) and bias type (float) should be the same"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from scipy.optimize import fmin\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Set file paths\n",
    "original_folder = r\"C:\\Users\\MAHESH\\Desktop\\SRFP INTERNSHIP\\train_in_1\\Raw\"\n",
    "output_folder = r\"C:\\Users\\MAHESH\\Desktop\\SRFP INTERNSHIP\\train_in_1\\Done\"\n",
    "csv_file_path = r\"C:\\Users\\MAHESH\\Desktop\\SRFP INTERNSHIP\\REPORTS\\gamma_values.csv\"\n",
    "input_image_path = r\"C:\\Users\\MAHESH\\Desktop\\SRFP INTERNSHIP\\photo-.jpg\"\n",
    "\n",
    "# Load gamma values from the CSV file\n",
    "gamma_df = pd.read_csv(csv_file_path)\n",
    "gamma_dict = dict(zip(gamma_df['file_name'], gamma_df['gamma_value']))\n",
    "\n",
    "# Define function to load, resize, and preprocess images\n",
    "def load_images(original_folder, output_folder, file_name):\n",
    "    original_path = os.path.join(original_folder, file_name)\n",
    "    enhanced_path = os.path.join(output_folder, file_name)\n",
    "\n",
    "    original_img = cv2.imread(original_path)\n",
    "    enhanced_img = cv2.imread(enhanced_path)\n",
    "\n",
    "    # Resize images\n",
    "    original_img = cv2.resize(original_img, (500, 500))\n",
    "    enhanced_img = cv2.resize(enhanced_img, (500, 500))\n",
    "\n",
    "    original_img = original_img / 255.0  # Normalize original image\n",
    "    enhanced_img = enhanced_img / 255.0  # Normalize enhanced image\n",
    "\n",
    "    return original_img, enhanced_img\n",
    "\n",
    "# Create custom dataset class\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, original_folder, output_folder, gamma_dict):\n",
    "        self.original_folder = original_folder\n",
    "        self.output_folder = output_folder\n",
    "        self.gamma_dict = gamma_dict\n",
    "        self.file_names = os.listdir(original_folder)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_names)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        file_name = self.file_names[index]\n",
    "        original_img, enhanced_img = load_images(self.original_folder, self.output_folder, file_name)\n",
    "        gamma = self.gamma_dict.get(file_name, 1.0)  # Default gamma value is 1.0 if not found in the dictionary\n",
    "\n",
    "        return torch.from_numpy(original_img).permute(2, 0, 1), torch.from_numpy(enhanced_img).permute(2, 0, 1), gamma\n",
    "\n",
    "# Create the training dataset\n",
    "dataset = ImageDataset(original_folder, output_folder, gamma_dict)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Define the model architecture\n",
    "class ImageEnhancementModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImageEnhancementModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.conv_gamma = nn.Conv2d(1, 32, 1)\n",
    "\n",
    "        self.concat = nn.Conv2d(64, 3, 3, padding=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input_image, input_gamma):\n",
    "        conv1 = nn.ReLU()(self.conv1(input_image))\n",
    "        conv2 = nn.ReLU()(self.conv2(conv1))\n",
    "        conv3 = nn.ReLU()(self.conv3(conv2))\n",
    "\n",
    "        conv_gamma = self.conv_gamma(input_gamma.repeat(1, conv3.size(2), conv3.size(3)).unsqueeze(1))\n",
    "\n",
    "        concat = torch.cat((conv3, conv_gamma), dim=1)\n",
    "\n",
    "        output = self.sigmoid(self.concat(concat))\n",
    "\n",
    "        return output\n",
    "\n",
    "# Build and train the model\n",
    "model = ImageEnhancementModel()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in dataloader:\n",
    "        original_images, output_images, gammas = batch\n",
    "        original_images = original_images.to(device)\n",
    "        output_images = output_images.to(device)\n",
    "        gammas = gammas.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        enhanced_images = model(original_images, gammas)\n",
    "        loss = criterion(enhanced_images, output_images)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Save the model weights\n",
    "torch.save(model.state_dict(), 'model_weights.pt')\n",
    "\n",
    "# Load the input image, resize, and preprocess it\n",
    "input_img = cv2.imread(input_image_path)\n",
    "input_img = cv2.resize(input_img, (500, 500))\n",
    "input_img = input_img / 255.0  # Normalize input image\n",
    "input_img = np.transpose(input_img, (2, 0, 1))  # Transpose image dimensions\n",
    "input_img = torch.from_numpy(input_img).unsqueeze(0).to(device)  # Add batch dimension and move to device\n",
    "\n",
    "# Get the optimal gamma value for the input image\n",
    "input_file_name = os.path.basename(input_image_path)\n",
    "optimal_gamma = gamma_dict.get(input_file_name, 1.0)  # Default gamma value is 1.0 if not found in the dictionary\n",
    "\n",
    "# Generate the enhanced image\n",
    "gamma_input = torch.tensor([[optimal_gamma]]).to(device)  # Convert gamma input to PyTorch tensor and move to device\n",
    "enhanced_img = model(input_img, gamma_input).squeeze().detach().cpu().numpy() * 255.0  # Denormalize and move to CPU\n",
    "enhanced_img = enhanced_img.transpose(1, 2, 0).astype(np.uint8)\n",
    "\n",
    "# Save the enhanced image\n",
    "output_image_path = os.path.join(output_folder, input_file_name)\n",
    "cv2.imwrite(output_image_path, enhanced_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3a93a7c",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [3, 4000, 6000] at entry 0 and [3, 2848, 4288] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 81>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m     82\u001b[0m     running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m---> 84\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m images_original, images_enhanced, gamma_values \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[0;32m     85\u001b[0m         images_original \u001b[38;5;241m=\u001b[39m images_original\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     86\u001b[0m         images_enhanced \u001b[38;5;241m=\u001b[39m images_enhanced\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32m~\\ansel\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\ansel\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\ansel\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\ansel\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;124;03m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;124;03m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\ansel\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:142\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    139\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\ansel\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:142\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    139\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\ansel\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:119\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 119\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    122\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32m~\\ansel\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:162\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    160\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    161\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[1;32m--> 162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [3, 4000, 6000] at entry 0 and [3, 2848, 4288] at entry 1"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "# Step 2: Define the dataset\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv_file, original_folder, enhanced_folder, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.original_folder = original_folder\n",
    "        self.enhanced_folder = enhanced_folder\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.data.loc[idx, 'file_name']\n",
    "        gamma_value = self.data.loc[idx, 'gamma_value']\n",
    "\n",
    "        original_image_path = os.path.join(self.original_folder, file_name)\n",
    "        enhanced_image_path = os.path.join(self.enhanced_folder, file_name)\n",
    "\n",
    "        original_image = Image.open(original_image_path).convert('RGB')\n",
    "        enhanced_image = Image.open(enhanced_image_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            original_image = self.transform(original_image)\n",
    "            enhanced_image = self.transform(enhanced_image)\n",
    "\n",
    "        return original_image, enhanced_image, gamma_value\n",
    "\n",
    "# Step 3: Define the CNN model\n",
    "class ImageEnhancer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImageEnhancer, self).__init__()\n",
    "\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(32 * 64 * 64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "\n",
    "# Step 4: Prepare the data and model\n",
    "csv_file = r\"C:\\Users\\MAHESH\\Desktop\\SRFP INTERNSHIP\\REPORTS\\gamma_values.csv\"\n",
    "original_folder = r\"C:\\Users\\MAHESH\\Desktop\\SRFP INTERNSHIP\\train_in_1\\Raw\"\n",
    "enhanced_folder = r\"C:\\Users\\MAHESH\\Desktop\\SRFP INTERNSHIP\\train_in_1\\Done\"\n",
    "\n",
    "dataset = ImageDataset(csv_file, original_folder, enhanced_folder, transform=ToTensor())\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = ImageEnhancer().to(device)\n",
    "\n",
    "# Step 5: Define the training loop\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images_original, images_enhanced, gamma_values in dataloader:\n",
    "        images_original = images_original.to(device)\n",
    "        images_enhanced = images_enhanced.to(device)\n",
    "        gamma_values = gamma_values.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images_original)\n",
    "        loss = criterion(outputs, gamma_values.unsqueeze(1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "# Step 6: Enhance an image\n",
    "def enhance_image(image_path):\n",
    "    model.eval()\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image_tensor = ToTensor()(image).unsqueeze(0).to(device)\n",
    "    enhanced_tensor = model(image_tensor)\n",
    "    enhanced_image = enhanced_tensor.squeeze(0).detach().cpu()\n",
    "\n",
    "    # Convert the tensor back to an image\n",
    "    enhanced_image = enhanced_image.permute(1, 2, 0).numpy()\n",
    "    enhanced_image = (enhanced_image * 255).astype(np.uint8)\n",
    "\n",
    "    return Image.fromarray(enhanced_image)\n",
    "\n",
    "# Example usage\n",
    "input_image_path = r\"C:\\Users\\MAHESH\\Desktop\\SRFP INTERNSHIP\\photo-.jpg\"\n",
    "enhanced_image = enhance_image(input_image_path)\n",
    "enhanced_image.save(r\"C:\\Users\\MAHESH\\Desktop\\SRFP INTERNSHIP\\photooooo.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de9752e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
