{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10da12a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "20/20 [==============================] - 259s 10s/step - loss: 0.0549\n",
      "Epoch 2/15\n",
      "20/20 [==============================] - 186s 9s/step - loss: 0.0256\n",
      "Epoch 3/15\n",
      "20/20 [==============================] - 185s 9s/step - loss: 0.0113\n",
      "Epoch 4/15\n",
      "20/20 [==============================] - 182s 9s/step - loss: 0.0096\n",
      "Epoch 5/15\n",
      "20/20 [==============================] - 190s 10s/step - loss: 0.0080\n",
      "Epoch 6/15\n",
      "20/20 [==============================] - 603s 31s/step - loss: 0.0079\n",
      "Epoch 7/15\n",
      "20/20 [==============================] - 188s 9s/step - loss: 0.0082\n",
      "Epoch 8/15\n",
      "20/20 [==============================] - 188s 9s/step - loss: 0.0081\n",
      "Epoch 9/15\n",
      "20/20 [==============================] - 185s 9s/step - loss: 0.0068\n",
      "Epoch 10/15\n",
      "20/20 [==============================] - 186s 9s/step - loss: 0.0076\n",
      "Epoch 11/15\n",
      "20/20 [==============================] - 227s 11s/step - loss: 0.0072\n",
      "Epoch 12/15\n",
      "20/20 [==============================] - 194s 10s/step - loss: 0.0070\n",
      "Epoch 13/15\n",
      "20/20 [==============================] - 187s 9s/step - loss: 0.0063\n",
      "Epoch 14/15\n",
      "20/20 [==============================] - 184s 9s/step - loss: 0.0064\n",
      "Epoch 15/15\n",
      "20/20 [==============================] - 184s 9s/step - loss: 0.0062\n",
      "1/1 [==============================] - 0s 324ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Set file paths\n",
    "original_folder = r\"C:\\Users\\MAHESH\\Desktop\\SRFP INTERNSHIP\\train_in_1\\Raw\"\n",
    "output_folder = r\"C:\\Users\\MAHESH\\Desktop\\SRFP INTERNSHIP\\train_in_1\\Done\"\n",
    "csv_file_path = r\"C:\\Users\\MAHESH\\Desktop\\SRFP INTERNSHIP\\REPORTS\\gamma_values.csv\"\n",
    "input_image_path = r\"C:\\Users\\MAHESH\\Desktop\\SRFP INTERNSHIP\\SRFP DAILY REPORTS\\SRFP FINAL REPORT\\Original Image.png\"\n",
    "\n",
    "# Load gamma values from the CSV file\n",
    "gamma_df = pd.read_csv(csv_file_path)\n",
    "gamma_dict = dict(zip(gamma_df['file_name'], gamma_df['gamma_value']))\n",
    "\n",
    "# Define function to load, resize, and preprocess images\n",
    "def load_images(original_folder, output_folder, file_name):\n",
    "    original_path = os.path.join(original_folder, file_name)\n",
    "    enhanced_path = os.path.join(output_folder, file_name)\n",
    "\n",
    "    original_img = cv2.imread(original_path)\n",
    "    enhanced_img = cv2.imread(enhanced_path)\n",
    "\n",
    "    # Resize images\n",
    "    original_img = cv2.resize(original_img, (500, 500))\n",
    "    enhanced_img = cv2.resize(enhanced_img, (500, 500))\n",
    "\n",
    "    original_img = original_img / 255.0  # Normalize original image\n",
    "    enhanced_img = enhanced_img / 255.0  # Normalize enhanced image\n",
    "\n",
    "    return original_img, enhanced_img\n",
    "\n",
    "# Create the training dataset\n",
    "input_images = []\n",
    "output_images = []\n",
    "gammas = []\n",
    "\n",
    "for file_name in os.listdir(original_folder):\n",
    "    original_img, enhanced_img = load_images(original_folder, output_folder, file_name)\n",
    "    gamma = gamma_dict.get(file_name, 1.0)  # Default gamma value is 1.0 if not found in the dictionary\n",
    "\n",
    "    input_images.append(original_img)\n",
    "    output_images.append(enhanced_img)\n",
    "    gammas.append(gamma)\n",
    "\n",
    "input_images = np.array(input_images)\n",
    "output_images = np.array(output_images)\n",
    "gammas = np.array(gammas)\n",
    "\n",
    "# Define the model architecture\n",
    "def build_model():\n",
    "    input_shape = (500, 500, 3)\n",
    "    input_image = Input(shape=input_shape, name='input_image')\n",
    "    input_gamma = Input(shape=(1,), name='input_gamma')\n",
    "\n",
    "    conv1 = Conv2D(32, 3, activation='relu', padding='same')(input_image)\n",
    "    conv2 = Conv2D(32, 3, activation='relu', padding='same')(conv1)\n",
    "    conv3 = Conv2D(32, 3, activation='relu', padding='same')(conv2)\n",
    "\n",
    "    conv_gamma = tf.repeat(input_gamma, tf.shape(conv3)[1]*tf.shape(conv3)[2])\n",
    "\n",
    "    conv_gamma = tf.reshape(conv_gamma, (-1, tf.shape(conv3)[1], tf.shape(conv3)[2], 1))\n",
    "\n",
    "    concat = concatenate([conv3, conv_gamma], axis=-1)\n",
    "\n",
    "    output = Conv2D(3, 3, activation='sigmoid', padding='same')(concat)\n",
    "\n",
    "    model = Model(inputs=[input_image, input_gamma], outputs=output)\n",
    "    model.compile(optimizer=Adam(lr=0.1), loss='mse')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# Build and train the model\n",
    "model = build_model()\n",
    "model.fit([input_images, gammas], output_images, batch_size=16, epochs=15)\n",
    "\n",
    "# Save the model weights\n",
    "model.save_weights('model_weights.h5')\n",
    "\n",
    "# Load the input image, resize, and preprocess it\n",
    "input_img = cv2.imread(input_image_path)\n",
    "input_img = cv2.resize(input_img, (500, 500))\n",
    "input_img = input_img / 255.0  # Normalize input image\n",
    "input_img = np.expand_dims(input_img, axis=0)  # Add batch dimension\n",
    "\n",
    "# Get the optimal gamma value for the input image\n",
    "input_file_name = os.path.basename(input_image_path)\n",
    "optimal_gamma = gamma_dict.get(input_file_name, 1.0)  # Default gamma value is 1.0 if not found in the dictionary\n",
    "\n",
    "# Generate the enhanced image\n",
    "# Generate the enhanced image\n",
    "gamma_input = np.array([[optimal_gamma]])  # Convert gamma input to NumPy array\n",
    "enhanced_img = model.predict([input_img, gamma_input])\n",
    "enhanced_img = enhanced_img[0] * 255.0  # Denormalize enhanced image\n",
    "enhanced_img = enhanced_img.astype(np.uint8)\n",
    "\n",
    "\n",
    "# Save the enhanced image\n",
    "output_image_path = os.path.join(output_folder, input_file_name)\n",
    "cv2.imwrite(output_image_path, enhanced_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1e5f5b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\MAHESH\\\\Desktop\\\\SRFP INTERNSHIP\\\\train_in_1\\\\Done\\\\Original Image.png'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5cd46f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 87  88  79]\n",
      "  [ 70  76  67]\n",
      "  [ 64  71  63]\n",
      "  ...\n",
      "  [ 72  79  70]\n",
      "  [ 75  85  73]\n",
      "  [100  98 103]]\n",
      "\n",
      " [[ 78  72  58]\n",
      "  [ 53  49  42]\n",
      "  [ 48  42  38]\n",
      "  ...\n",
      "  [ 62  55  49]\n",
      "  [ 64  63  55]\n",
      "  [ 89  80  87]]\n",
      "\n",
      " [[ 71  64  51]\n",
      "  [ 46  40  34]\n",
      "  [ 41  33  31]\n",
      "  ...\n",
      "  [ 57  46  42]\n",
      "  [ 61  55  50]\n",
      "  [ 84  74  85]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 54  58  44]\n",
      "  [ 26  31  26]\n",
      "  [ 20  26  23]\n",
      "  ...\n",
      "  [ 19  34  36]\n",
      "  [ 25  40  40]\n",
      "  [ 56  63  80]]\n",
      "\n",
      " [[ 59  61  48]\n",
      "  [ 31  37  29]\n",
      "  [ 25  32  28]\n",
      "  ...\n",
      "  [ 24  38  38]\n",
      "  [ 30  44  42]\n",
      "  [ 60  69  82]]\n",
      "\n",
      " [[ 74  88  69]\n",
      "  [ 46  66  50]\n",
      "  [ 43  62  49]\n",
      "  ...\n",
      "  [ 40  64  55]\n",
      "  [ 47  69  61]\n",
      "  [ 72  88  88]]]\n"
     ]
    }
   ],
   "source": [
    "print(enhanced_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4db4da77",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image_path = r\"C:\\Users\\MAHESH\\Desktop\\SRFP INTERNSHIP\\REPORTS\\FNfo7r.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b2107b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "39/39 [==============================] - 193s 5s/step - loss: 0.0469\n",
      "Epoch 2/80\n",
      "39/39 [==============================] - 191s 5s/step - loss: 0.0118\n",
      "Epoch 3/80\n",
      "39/39 [==============================] - 4589s 121s/step - loss: 0.0080\n",
      "Epoch 4/80\n",
      "39/39 [==============================] - 187s 5s/step - loss: 0.0082\n",
      "Epoch 5/80\n",
      "39/39 [==============================] - 187s 5s/step - loss: 0.0068\n",
      "Epoch 6/80\n",
      "39/39 [==============================] - 183s 5s/step - loss: 0.0066\n",
      "Epoch 7/80\n",
      "39/39 [==============================] - 184s 5s/step - loss: 0.0073\n",
      "Epoch 8/80\n",
      "39/39 [==============================] - 185s 5s/step - loss: 0.0070\n",
      "Epoch 9/80\n",
      "39/39 [==============================] - 186s 5s/step - loss: 0.0083\n",
      "Epoch 10/80\n",
      "39/39 [==============================] - 5758s 151s/step - loss: 0.0066\n",
      "Epoch 11/80\n",
      "39/39 [==============================] - 184s 5s/step - loss: 0.0058\n",
      "Epoch 12/80\n",
      "39/39 [==============================] - 182s 5s/step - loss: 0.0060\n",
      "Epoch 13/80\n",
      "39/39 [==============================] - 182s 5s/step - loss: 0.0062\n",
      "Epoch 14/80\n",
      "39/39 [==============================] - 182s 5s/step - loss: 0.0068\n",
      "Epoch 15/80\n",
      "39/39 [==============================] - 20009s 526s/step - loss: 0.0055\n",
      "Epoch 16/80\n",
      "39/39 [==============================] - 205s 5s/step - loss: 0.0056\n",
      "Epoch 17/80\n",
      "39/39 [==============================] - 203s 5s/step - loss: 0.0057\n",
      "Epoch 18/80\n",
      "39/39 [==============================] - 26247s 691s/step - loss: 0.0054\n",
      "Epoch 19/80\n",
      "39/39 [==============================] - 229s 6s/step - loss: 0.0058\n",
      "Epoch 20/80\n",
      "39/39 [==============================] - 227s 6s/step - loss: 0.0053\n",
      "Epoch 21/80\n",
      "39/39 [==============================] - 204s 5s/step - loss: 0.0059\n",
      "Epoch 22/80\n",
      "39/39 [==============================] - 944s 25s/step - loss: 0.0057\n",
      "Epoch 23/80\n",
      "39/39 [==============================] - 198s 5s/step - loss: 0.0056\n",
      "Epoch 24/80\n",
      "39/39 [==============================] - 219s 6s/step - loss: 0.0057\n",
      "Epoch 25/80\n",
      "39/39 [==============================] - 222s 6s/step - loss: 0.0055\n",
      "Epoch 26/80\n",
      "39/39 [==============================] - 214s 6s/step - loss: 0.0058\n",
      "Epoch 27/80\n",
      "39/39 [==============================] - 212s 5s/step - loss: 0.0054\n",
      "Epoch 28/80\n",
      "39/39 [==============================] - 215s 6s/step - loss: 0.0054\n",
      "Epoch 29/80\n",
      "39/39 [==============================] - 219s 6s/step - loss: 0.0052\n",
      "Epoch 30/80\n",
      "39/39 [==============================] - 223s 6s/step - loss: 0.0053\n",
      "Epoch 31/80\n",
      "39/39 [==============================] - 235s 6s/step - loss: 0.0061\n",
      "Epoch 32/80\n",
      "39/39 [==============================] - 218s 6s/step - loss: 0.0054\n",
      "Epoch 33/80\n",
      "39/39 [==============================] - 215s 6s/step - loss: 0.0056\n",
      "Epoch 34/80\n",
      "39/39 [==============================] - 193s 5s/step - loss: 0.0051\n",
      "Epoch 35/80\n",
      "39/39 [==============================] - 196s 5s/step - loss: 0.0057\n",
      "Epoch 36/80\n",
      "39/39 [==============================] - 197s 5s/step - loss: 0.0058\n",
      "Epoch 37/80\n",
      "39/39 [==============================] - 254s 7s/step - loss: 0.0052\n",
      "Epoch 38/80\n",
      "39/39 [==============================] - 245s 6s/step - loss: 0.0050\n",
      "Epoch 39/80\n",
      "39/39 [==============================] - 225s 6s/step - loss: 0.0055\n",
      "Epoch 40/80\n",
      "39/39 [==============================] - 247s 6s/step - loss: 0.0049\n",
      "Epoch 41/80\n",
      "39/39 [==============================] - 247s 6s/step - loss: 0.0049\n",
      "Epoch 42/80\n",
      "39/39 [==============================] - 235s 6s/step - loss: 0.0053\n",
      "Epoch 43/80\n",
      "39/39 [==============================] - 224s 6s/step - loss: 0.0051\n",
      "Epoch 44/80\n",
      "39/39 [==============================] - 241s 6s/step - loss: 0.0054\n",
      "Epoch 45/80\n",
      "39/39 [==============================] - 294s 8s/step - loss: 0.0052\n",
      "Epoch 46/80\n",
      "39/39 [==============================] - 292s 7s/step - loss: 0.0049\n",
      "Epoch 47/80\n",
      "39/39 [==============================] - 274s 7s/step - loss: 0.0048\n",
      "Epoch 48/80\n",
      "39/39 [==============================] - 319s 8s/step - loss: 0.0049\n",
      "Epoch 49/80\n",
      "39/39 [==============================] - 313s 8s/step - loss: 0.0048\n",
      "Epoch 50/80\n",
      "39/39 [==============================] - 220s 6s/step - loss: 0.0051\n",
      "Epoch 51/80\n",
      "39/39 [==============================] - 199s 5s/step - loss: 0.0050\n",
      "Epoch 52/80\n",
      "39/39 [==============================] - 221s 6s/step - loss: 0.0051\n",
      "Epoch 53/80\n",
      "39/39 [==============================] - 197s 5s/step - loss: 0.0052\n",
      "Epoch 54/80\n",
      "39/39 [==============================] - 206s 5s/step - loss: 0.0048\n",
      "Epoch 55/80\n",
      "39/39 [==============================] - 198s 5s/step - loss: 0.0048\n",
      "Epoch 56/80\n",
      "39/39 [==============================] - 208s 5s/step - loss: 0.0051\n",
      "Epoch 57/80\n",
      "39/39 [==============================] - 194s 5s/step - loss: 0.0052\n",
      "Epoch 58/80\n",
      "39/39 [==============================] - 197s 5s/step - loss: 0.0050\n",
      "Epoch 59/80\n",
      "39/39 [==============================] - 209s 5s/step - loss: 0.0050\n",
      "Epoch 60/80\n",
      "39/39 [==============================] - 195s 5s/step - loss: 0.0047\n",
      "Epoch 61/80\n",
      "39/39 [==============================] - 217s 6s/step - loss: 0.0050\n",
      "Epoch 62/80\n",
      "39/39 [==============================] - 212s 5s/step - loss: 0.0047\n",
      "Epoch 63/80\n",
      "39/39 [==============================] - 206s 5s/step - loss: 0.0048\n",
      "Epoch 64/80\n",
      "39/39 [==============================] - 227s 6s/step - loss: 0.0051\n",
      "Epoch 65/80\n",
      "39/39 [==============================] - 210s 5s/step - loss: 0.0048\n",
      "Epoch 66/80\n",
      "39/39 [==============================] - 204s 5s/step - loss: 0.0048\n",
      "Epoch 67/80\n",
      "39/39 [==============================] - 231s 6s/step - loss: 0.0047\n",
      "Epoch 68/80\n",
      "39/39 [==============================] - 216s 6s/step - loss: 0.0051\n",
      "Epoch 69/80\n",
      "39/39 [==============================] - 204s 5s/step - loss: 0.0047\n",
      "Epoch 70/80\n",
      "39/39 [==============================] - 223s 6s/step - loss: 0.0049\n",
      "Epoch 71/80\n",
      "39/39 [==============================] - 213s 5s/step - loss: 0.0048\n",
      "Epoch 72/80\n",
      "39/39 [==============================] - 223s 6s/step - loss: 0.0049\n",
      "Epoch 73/80\n",
      "39/39 [==============================] - 211s 5s/step - loss: 0.0047\n",
      "Epoch 74/80\n",
      "39/39 [==============================] - 204s 5s/step - loss: 0.0045\n",
      "Epoch 75/80\n",
      "39/39 [==============================] - 205s 5s/step - loss: 0.0049\n",
      "Epoch 76/80\n",
      "39/39 [==============================] - 216s 6s/step - loss: 0.0049\n",
      "Epoch 77/80\n",
      "39/39 [==============================] - 202s 5s/step - loss: 0.0048\n",
      "Epoch 78/80\n",
      "39/39 [==============================] - 207s 5s/step - loss: 0.0046\n",
      "Epoch 79/80\n",
      "39/39 [==============================] - 226s 6s/step - loss: 0.0047\n",
      "Epoch 80/80\n",
      "39/39 [==============================] - 221s 6s/step - loss: 0.0046\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001EB43F2AF80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001EB43F2AF80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 357ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Set file paths\n",
    "original_folder = r\"C:\\Users\\MAHESH\\Desktop\\SRFP INTERNSHIP\\train_in_1\\Raw\"\n",
    "output_folder = r\"C:\\Users\\MAHESH\\Desktop\\SRFP INTERNSHIP\\train_in_1\\Done\"\n",
    "csv_file_path = r\"C:\\Users\\MAHESH\\Desktop\\SRFP INTERNSHIP\\REPORTS\\gamma_values.csv\"\n",
    "input_image_path = r\"C:\\Users\\MAHESH\\Pictures\\ATIFR 2022\\243.jpeg\"\n",
    "\n",
    "# Load gamma values from the CSV file\n",
    "gamma_df = pd.read_csv(csv_file_path)\n",
    "gamma_dict = dict(zip(gamma_df['file_name'], gamma_df['gamma_value']))\n",
    "\n",
    "# Define function to load, resize, and preprocess images\n",
    "def load_images(original_folder, output_folder, file_name):\n",
    "    original_path = os.path.join(original_folder, file_name)\n",
    "    enhanced_path = os.path.join(output_folder, file_name)\n",
    "\n",
    "    original_img = cv2.imread(original_path)\n",
    "    enhanced_img = cv2.imread(enhanced_path)\n",
    "\n",
    "    # Resize images\n",
    "    original_img = cv2.resize(original_img, (500, 500))\n",
    "    enhanced_img = cv2.resize(enhanced_img, (500, 500))\n",
    "\n",
    "    original_img = original_img / 255.0  # Normalize original image\n",
    "    enhanced_img = enhanced_img / 255.0  # Normalize enhanced image\n",
    "\n",
    "    return original_img, enhanced_img\n",
    "\n",
    "# Create the training dataset\n",
    "input_images = []\n",
    "output_images = []\n",
    "gammas = []\n",
    "\n",
    "for file_name in os.listdir(original_folder):\n",
    "    original_img, enhanced_img = load_images(original_folder, output_folder, file_name)\n",
    "    gamma = gamma_dict.get(file_name, 1.0)  # Default gamma value is 1.0 if not found in the dictionary\n",
    "\n",
    "    input_images.append(original_img)\n",
    "    output_images.append(enhanced_img)\n",
    "    gammas.append(gamma)\n",
    "\n",
    "input_images = np.array(input_images)\n",
    "output_images = np.array(output_images)\n",
    "gammas = np.array(gammas)\n",
    "\n",
    "# Define the model architecture\n",
    "def build_model():\n",
    "    input_shape = (500, 500, 3)\n",
    "    input_image = Input(shape=input_shape, name='input_image')\n",
    "    input_gamma = Input(shape=(1,), name='input_gamma')\n",
    "\n",
    "    conv1 = Conv2D(32, 3, activation='relu', padding='same')(input_image)\n",
    "    conv2 = Conv2D(32, 3, activation='relu', padding='same')(conv1)\n",
    "    conv3 = Conv2D(32, 3, activation='relu', padding='same')(conv2)\n",
    "\n",
    "    conv_gamma = tf.repeat(input_gamma, tf.shape(conv3)[1]*tf.shape(conv3)[2])\n",
    "\n",
    "    conv_gamma = tf.reshape(conv_gamma, (-1, tf.shape(conv3)[1], tf.shape(conv3)[2], 1))\n",
    "\n",
    "    concat = concatenate([conv3, conv_gamma], axis=-1)\n",
    "\n",
    "    output = Conv2D(3, 3, activation='sigmoid', padding='same')(concat)\n",
    "\n",
    "    model = Model(inputs=[input_image, input_gamma], outputs=output)\n",
    "    model.compile(optimizer=Adam(lr=0.1), loss='mse')\n",
    "\n",
    "    return model\n",
    "\n",
    "# Build and train the model\n",
    "model = build_model()\n",
    "model.fit([input_images, gammas], output_images, batch_size=8, epochs=80)\n",
    "\n",
    "# Save the model weights\n",
    "model.save_weights('model_weights.h5')\n",
    "\n",
    "# Load the input image, resize, and preprocess it\n",
    "input_img = cv2.imread(input_image_path)\n",
    "input_img = cv2.resize(input_img, (500, 500))\n",
    "input_img = input_img / 255.0  # Normalize input image\n",
    "input_img = np.expand_dims(input_img, axis=0)  # Add batch dimension\n",
    "\n",
    "# Get the optimal gamma value for the input image\n",
    "input_file_name = os.path.basename(input_image_path)\n",
    "optimal_gamma = gamma_dict.get(input_file_name, 1.0)  # Default gamma value is 1.0 if not found in the dictionary\n",
    "\n",
    "# Generate the enhanced image\n",
    "gamma_input = np.array([[optimal_gamma]])  # Convert gamma input to NumPy array\n",
    "enhanced_img = model.predict([input_img, gamma_input])\n",
    "enhanced_img = enhanced_img[0] * 255.0  # Denormalize enhanced image\n",
    "enhanced_img = enhanced_img.astype(np.uint8)\n",
    "\n",
    "# Save the enhanced image\n",
    "output_image_path = os.path.join(output_folder, input_file_name)\n",
    "cv2.imwrite(output_image_path, enhanced_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acc86d49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\MAHESH\\\\Desktop\\\\SRFP INTERNSHIP\\\\train_in_1\\\\Done\\\\243.jpeg'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6893d2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20/20 [==============================] - 211s 9s/step - loss: 0.0447\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 179s 9s/step - loss: 0.0220\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 176s 9s/step - loss: 0.0124\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 177s 9s/step - loss: 0.0087\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 178s 9s/step - loss: 0.0081\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 177s 9s/step - loss: 0.0077\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 177s 9s/step - loss: 0.0080\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 192s 10s/step - loss: 0.0079\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 201s 10s/step - loss: 0.0074\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 178s 9s/step - loss: 0.0073\n",
      "1/1 [==============================] - 0s 468ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Set file paths\n",
    "original_folder = r\"C:\\Users\\MAHESH\\Desktop\\SRFP INTERNSHIP\\train_in_1\\Raw\"\n",
    "output_folder = r\"C:\\Users\\MAHESH\\Desktop\\SRFP INTERNSHIP\\train_in_1\\Done\"\n",
    "csv_file_path = r\"C:\\Users\\MAHESH\\Desktop\\SRFP INTERNSHIP\\REPORTS\\gamma_values.csv\"\n",
    "input_image_path = r\"C:\\Users\\MAHESH\\Desktop\\SRFP INTERNSHIP\\SRFP DAILY REPORTS\\SRFP FINAL REPORT\\Man-doing-postproduction-of-his-photos-on-laptop-at-night-By-Carina-Konig.jpg\"\n",
    "\n",
    "# Load gamma values from the CSV file\n",
    "gamma_df = pd.read_csv(csv_file_path)\n",
    "gamma_dict = dict(zip(gamma_df['file_name'], gamma_df['gamma_value']))\n",
    "\n",
    "# Define function to load, resize, and preprocess images\n",
    "def load_images(original_folder, output_folder, file_name):\n",
    "    original_path = os.path.join(original_folder, file_name)\n",
    "    enhanced_path = os.path.join(output_folder, file_name)\n",
    "\n",
    "    original_img = cv2.imread(original_path)\n",
    "    enhanced_img = cv2.imread(enhanced_path)\n",
    "\n",
    "    # Resize images\n",
    "    original_img = cv2.resize(original_img, (500, 500))\n",
    "    enhanced_img = cv2.resize(enhanced_img, (500, 500))\n",
    "\n",
    "    original_img = original_img / 255.0  # Normalize original image\n",
    "    enhanced_img = enhanced_img / 255.0  # Normalize enhanced image\n",
    "\n",
    "    return original_img, enhanced_img\n",
    "\n",
    "# Create the training dataset\n",
    "input_images = []\n",
    "output_images = []\n",
    "gammas = []\n",
    "\n",
    "for file_name in os.listdir(original_folder):\n",
    "    original_img, enhanced_img = load_images(original_folder, output_folder, file_name)\n",
    "    gamma = gamma_dict.get(file_name, 1.0)  # Default gamma value is 1.0 if not found in the dictionary\n",
    "\n",
    "    input_images.append(original_img)\n",
    "    output_images.append(enhanced_img)\n",
    "    gammas.append(gamma)\n",
    "\n",
    "input_images = np.array(input_images)\n",
    "output_images = np.array(output_images)\n",
    "gammas = np.array(gammas)\n",
    "\n",
    "# Define the model architecture\n",
    "def build_model():\n",
    "    input_shape = (500, 500, 3)\n",
    "    input_image = Input(shape=input_shape, name='input_image')\n",
    "    input_gamma = Input(shape=(1,), name='input_gamma')\n",
    "\n",
    "    conv1 = Conv2D(32, 3, activation='linear', padding='same')(input_image)\n",
    "    conv2 = Conv2D(32, 3, activation='linear', padding='same')(conv1)\n",
    "    conv3 = Conv2D(32, 3, activation='linear', padding='same')(conv2)\n",
    "\n",
    "    conv_gamma = tf.repeat(input_gamma, tf.shape(conv3)[1]*tf.shape(conv3)[2])\n",
    "\n",
    "    conv_gamma = tf.reshape(conv_gamma, (-1, tf.shape(conv3)[1], tf.shape(conv3)[2], 1))\n",
    "\n",
    "    concat = concatenate([conv3, conv_gamma], axis=-1)\n",
    "\n",
    "    output = Conv2D(3, 3, activation='sigmoid', padding='same')(concat)\n",
    "\n",
    "    model = Model(inputs=[input_image, input_gamma], outputs=output)\n",
    "    model.compile(optimizer=Adam(lr=0.1), loss='mse')\n",
    "\n",
    "    return model\n",
    "\n",
    "# Build and train the model\n",
    "model = build_model()\n",
    "model.fit([input_images, gammas], output_images, batch_size=16, epochs=10)\n",
    "\n",
    "# Save the model weights\n",
    "model.save_weights('model_weights.h5')\n",
    "\n",
    "# Load the input image, resize, and preprocess it\n",
    "input_img = cv2.imread(input_image_path)\n",
    "input_img = cv2.resize(input_img, (500, 500))\n",
    "input_img = input_img / 255.0  # Normalize input image\n",
    "input_img = np.expand_dims(input_img, axis=0)  # Add batch dimension\n",
    "\n",
    "# Get the optimal gamma value for the input image\n",
    "input_file_name = os.path.basename(input_image_path)\n",
    "optimal_gamma = gamma_dict.get(input_file_name, 1.0)  # Default gamma value is 1.0 if not found in the dictionary\n",
    "\n",
    "# Generate the enhanced image\n",
    "gamma_input = np.array([[optimal_gamma]])  # Convert gamma input to NumPy array\n",
    "enhanced_img = model.predict([input_img, gamma_input])\n",
    "enhanced_img = enhanced_img[0] * 255.0  # Denormalize enhanced image\n",
    "enhanced_img = enhanced_img.astype(np.uint8)\n",
    "\n",
    "# Save the enhanced image\n",
    "output_image_path = os.path.join(output_folder, input_file_name)\n",
    "cv2.imwrite(output_image_path, enhanced_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28fcaff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\MAHESH\\\\Desktop\\\\SRFP INTERNSHIP\\\\train_in_1\\\\Done\\\\243.jpeg'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aced65d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
